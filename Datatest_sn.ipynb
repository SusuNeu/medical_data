{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gdown\n",
    "import plotly.express as px\n",
    "from io import StringIO\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import os\n",
    "import nibabel as nib\n",
    "import requests\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "csv_url = \"https://raw.githubusercontent.com/karimconf/medical_data/main/Train_sexAge.csv\"\n",
    "\n",
    "# Make a request to the URL and get the content\n",
    "response = requests.get(csv_url)\n",
    "content = response.text\n",
    "\n",
    "# Use pandas to read the CSV data\n",
    "df = pd.read_csv(StringIO(content))\n",
    "df = df.drop('Unnamed: 4', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_repo_url = \"https://raw.githubusercontent.com/karimconf/medical_data/main/Train/\"\n",
    "df['image_link'] = df['ID'].apply(lambda x: f\"{github_repo_url}areg_{x}_brain.nii.gz\")\n",
    "\n",
    "count_by_sex = df[df['target'].isin(['ADHD', 'hCon'])].groupby(['target', 'Sex']).size().reset_index(name='count')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display the result\n",
    "print(count_by_sex)\n",
    "df.head()\n",
    "\n",
    "\n",
    "adhd_data = df[df['target'] == 'ADHD'].sort_values(by=['Sex', 'Age'])\n",
    "hcon_data = df[df['target'] == 'hCon'].sort_values(by=['Sex', 'Age'])\n",
    "\n",
    "fig_adhd = px.bar(adhd_data, x='ID', y='Age', color='Sex', title='ADHD Data',\n",
    "                  hover_data=['Sex', 'Age', 'image_link'])\n",
    "fig_hcon = px.bar(hcon_data, x='ID', y='Age', color='Sex', title='hCon Data',\n",
    "                  hover_data=['Sex', 'Age', 'image_link'])\n",
    "\n",
    "# Show the plots\n",
    "fig_adhd.show()\n",
    "fig_hcon.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"ADHD : \",adhd_data.describe())\n",
    "\n",
    "print(\"hCon : \",hcon_data.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nii_files = [\n",
    "    \"https://raw.githubusercontent.com/karimconf/medical_data/main/Train/areg_ADHD_1189_brain.nii.gz\",\n",
    "    \"https://raw.githubusercontent.com/karimconf/medical_data/main/Train/areg_hCon_1012_brain.nii.gz\"\n",
    "]\n",
    "# Create a temporary directory to store downloaded files\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "# Create a single plot with two subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=(6, 5))  # Adjust the figsize as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each NIfTI file\n",
    "for i, nii_file_url in enumerate(nii_files):\n",
    "    try:\n",
    "        # Download the file content\n",
    "        response = requests.get(nii_file_url)\n",
    "        response.raise_for_status()  # Raise an error for bad responses\n",
    "        file_content = response.content\n",
    "\n",
    "        # Save the content to a temporary file\n",
    "        temp_file_path = os.path.join(temp_dir, f\"temp_nii_{i}.nii.gz\")\n",
    "        with open(temp_file_path, \"wb\") as temp_file:\n",
    "            temp_file.write(file_content)\n",
    "\n",
    "        # Load NIfTI image using nibabel\n",
    "        nii_image = nib.load(temp_file_path)\n",
    "\n",
    "        # Get the NIfTI image data as a 3D NumPy array\n",
    "        image_data = nii_image.get_fdata()\n",
    "\n",
    "        # Display the NIfTI image in a subplot\n",
    "        axs[i].imshow(image_data[:, :, image_data.shape[2] // 2],\n",
    "                      extent=[0, image_data.shape[1], 0, image_data.shape[0]],\n",
    "                      cmap='gray', aspect='equal')\n",
    "        axs[i].set_title(os.path.basename(nii_file_url))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {nii_file_url}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up temporary directory\n",
    "for file_path in os.listdir(temp_dir):\n",
    "    os.remove(os.path.join(temp_dir, file_path))\n",
    "os.rmdir(temp_dir)\n",
    "image_data = []\n",
    "labels = []\n",
    "temp_dir = tempfile.mkdtemp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            nii_file_url = row['image_link']\n",
    "            response = requests.get(nii_file_url)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            # Save the NIfTI file content to a temporary file\n",
    "            temp_file_path = os.path.join(temp_dir, f\"temp_nii_{index}.nii.gz\")\n",
    "            with open(temp_file_path, \"wb\") as temp_file:\n",
    "                temp_file.write(response.content)\n",
    "\n",
    "            # Load NIfTI image using nibabel\n",
    "            nii_image = nib.load(temp_file_path)\n",
    "            nii_array = np.asarray(nii_image.get_fdata())\n",
    "\n",
    "            image_data.append(nii_array)\n",
    "            labels.append(row['target'])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {nii_file_url}: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Clean up temporary directory\n",
    "    for file_path in os.listdir(temp_dir):\n",
    "        os.remove(os.path.join(temp_dir, file_path))\n",
    "    os.rmdir(temp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "encoded_labels_categorical = to_categorical(encoded_labels)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    np.array(image_data), encoded_labels_categorical, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Reshape data to explicitly include the depth dimension\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2], X_train.shape[3], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2], X_test.shape[3], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LeNet model with Conv3D layers\n",
    "lenet_model = models.Sequential([\n",
    "    layers.Conv3D(6, (3, 3, 3), activation='relu', input_shape=X_train.shape[1:]),\n",
    "    layers.AveragePooling3D(),\n",
    "    layers.Conv3D(16, (3, 3, 3), activation='relu'),\n",
    "    layers.AveragePooling3D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(120, activation='relu'),\n",
    "    layers.Dense(84, activation='relu'),\n",
    "    layers.Dense(2, activation='softmax')  # Assuming 2 classes (ADHD and hCon)\n",
    "])\n",
    "\n",
    "# Compile the LeNet model\n",
    "lenet_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the LeNet model\n",
    "lenet_model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the LeNet model on the test set\n",
    "lenet_test_loss, lenet_test_accuracy = lenet_model.evaluate(X_test, y_test)\n",
    "print(f'LeNet Test Accuracy: {lenet_test_accuracy * 100:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Dense model\n",
    "dense_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the Dense model\n",
    "dense_model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the Dense model on the test set\n",
    "dense_test_loss, dense_test_accuracy = dense_model.evaluate(X_test, y_test)\n",
    "print(f'Dense Model Test Accuracy: {dense_test_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN model\n",
    "cnn_model = models.Sequential([\n",
    "    layers.Conv3D(32, (3, 3, 3), activation='relu', input_shape=X_train.shape[1:]),\n",
    "    layers.MaxPooling3D((2, 2, 2)),\n",
    "    layers.Conv3D(64, (3, 3, 3), activation='relu'),\n",
    "    layers.MaxPooling3D((2, 2, 2)),\n",
    "    layers.Conv3D(64, (3, 3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(2, activation='softmax')  # Assuming 2 classes (ADHD and hCon)\n",
    "])\n",
    "\n",
    "# Compile the CNN model\n",
    "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the CNN model\n",
    "cnn_model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the CNN model on the test set\n",
    "cnn_test_loss, cnn_test_accuracy = cnn_model.evaluate(X_test, y_test)\n",
    "print(f'CNN Model Test Accuracy: {cnn_test_accuracy * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
